
🚀 Excited to share a simple gradient descent implementation for linear regression using PyTorch! 🤖💡

🔍 In this code snippet, I implemented a basic linear regression model and optimized it using gradient descent. It's a hands-on way to understand the mechanics of training a model to minimize a loss function. The code includes manual weight and bias initialization, a custom mean squared error loss function, and the optimization loop.

🧠 Learning Highlights:

Manual Initialization: We start with manually set weights and biases. In practice, these are often initialized randomly and learned during training.

Learning Rate Tuning: The learning rate plays a crucial role in optimization. Here, it's set to 1e-5.

Iterations: The model undergoes optimization for a set number of iterations (m), a critical aspect of training.

Dataset :

![image](https://github.com/eclipse-dt/ML_init_grad_descent_optim/assets/139947052/0ea8842d-3aeb-41a8-b9a2-03184d2e9b3d)


Predictions model:

yield_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1

yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2
